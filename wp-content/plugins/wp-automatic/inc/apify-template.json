{
  "runMode": "DEVELOPMENT",
  "startUrls": [
    {
      "url": "https://www.example.com",
      "method": "GET"
    }
  ],
  "keepUrlFragments": false,
  "linkSelector": "a[href]",
  "pseudoUrls": [
    {
      "purl": "https://apify.com[(/[\\w-]+)?]"
    }
  ],
  "pageFunction": "// The function accepts a single argument: the \"context\" object.\n// For a complete list of its properties and functions,\n// see https://apify.com/apify/web-scraper#page-function \nasync function pageFunction(context) {\n    // This statement works as a breakpoint when you're trying to debug your code. Works only with Run mode: DEVELOPMENT!\n    // debugger; \n\n    // jQuery is handy for finding DOM elements and extracting data from them.\n    // To use it, make sure to enable the \"Inject jQuery\" option.\n    const $ = context.jQuery;\n    const pageTitle = $('title').first().text();\n    const pageContent = $('html').html();\n\n    // Print some information to actor log\n    context.log.info(`URL: ${context.request.url}, TITLE: ${pageTitle}`);\n\n    // Manually add a new page to the queue for scraping.\n    // To make this work, make sure the \"Use request queue\" option is enabled.\n    //context.enqueueRequest({ url: 'http://www.example.com' });\n\n    // Return an object with the data extracted from the page.\n    // It will be stored to the resulting dataset.\n    return {\n         url: context.request.url,\n       pageContent\n    };\n}",
  "injectJQuery": true,
  "injectUnderscore": false,
  "proxyConfiguration": {
    "useApifyProxy": false
  },
  "proxyRotation": "RECOMMENDED",
  "useChrome": false,
  "useStealth": false,
  "ignoreSslErrors": false,
  "ignoreCorsAndCsp": false,
  "downloadMedia": false,
  "downloadCss": false,
  "waitUntil": [
    "networkidle2"
  ],
  "breakpointLocation": "NONE",
  "debugLog": false,
  "browserLog": false
}